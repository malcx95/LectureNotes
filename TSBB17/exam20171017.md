# 1.

The spatial pyramid pooling layer performs pooling of a feature map at different scales.
It pools with a certain kernel size, producing a certain number of bins, using for example
max or average pooling. Then it pools at a larger kernel size, producing a fewer number of
bins. This is repeated until possibly the kernel is as big as the feature map, producing
only one bin. These bins are then concatenated to a fixed-length vector which is then
fed to the fully connected layers. This way, the pooling layer can accept inputs of 
variable sizes and output a fixed size representation, which is neccessary for the 
fully-connected layers.

# 2.

Percieved image intensities -> Edges, blobs, lines -> Depth distinction -> 3D model

# 3.

Both input some image information and outputs a location of an object. Detection inputs
only an image and outputs a location of an object, while tracking inputs a description
or image of what is to be tracked, and outputs a location of the tracked object in 
a series of subsequent frames.

# 4.

A visual word is a feature that has been approximated by quantizing the descriptor space.
They contain no information about location. They are computed by quantizing the
space of some descriptor, whitening the space and then approximating a descriptor
to a visual word vector.

# 5.

ReLU does't suffer from the vanishing gradient problem. It also allows the activations
of the net to be sparse, which is more efficient than dense activations.

# 6.

CNN:s gives us sparse representations of the images, which is much more 
statistically efficient than i.e. fully connected networks, leading to less overfitting.
CNN:s can learn features, meaning we don't need to use hand-crafted features.

# 7.

The training data is used to train the CNN, i.e. this is the dataset the cost function
is minimized with respect to. The validation data is used to test the network at various
stages during the training, to make sure that the network's generalization ability stays
improves during training.

# 8.

The dropout layer randomly sets some of the neurons to 0 during training. This prevents
overfitting, by forcing the network to learn more robust features.

# 9.

To reduce overfitting in the network and improve stability.

# 10.

Minimum Output Sum of Squared Error. This means that MOSSE is a DCF derived from

```
min_H sum_i (Fi o H - Gi)^2
```

which means that the MOSSE filter is a correlation filter that minimizes the squared
difference between the filter applied on the training inputs to the desired outputs.

# 11.

Continuous Convolution Operators allows for joint fusion of multi-resolution feature
maps without the need for resampling. It also provides sub-pixel precision.

# 12.

To keep the feature map at the same size after a convolution.

# 13.

Support vector machines is a form of linear trainable classifier, which aims to
separate classes with as much margin as possible.

# 14.

If the network didn't have activation functions, then each layer would be a simple
linear combination. Combining several of these layers would result in the entire network
being linear, which would be equivalent to just one linear combination, i.e. one layer.

# 15.

The validation set is used to detect overfitting/underfitting by testing the network
on it and comparing to the training error. If the training error is low but the error
on the validation set is high, the model is overfitted. On the other hand, if both
the training error and validation error is high, the model is underfitted, and
would benefit from more training or more complicated network.

# 16.

Higher strides can give better statistical efficiency, as only the "important"
features are kept. It also reduces computational cost.

